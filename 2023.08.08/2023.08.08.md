1. Grid Search
   1. 하이퍼 파라미터를 설정하는 것은 모델링에서 매우 중요한 일
   2. 관계있는 하이퍼 파라미터들을  대상으로 가능한 모든 조합을 시도하는 것
   3. 장점으로 최적의 하이퍼 파라미터를 설정할 수 있지만 시간이 오래걸린다는 단점이 있다.
2. 회귀
   1. 연속적인 실수 값을 예측하는 분야
   2. 직선의 형태를 가지는 1차식으로 연속적인 실수 값을 예측하는 모델
   3. 데이터의 분포를 가장 잘 표현할 수 있는 직선(y= wx+b)을 그려서 값을 예측하는 방법
   4. 선형회귀는 무조건 2차로 값을 넣어야 한다. 
3. mse
   1. 모델 성능 평가지표의 하나이다.
   2. 분산과 같다.
4. rmse
   1. mse에 제곱근을 씌운 것
   2. 표준편차와 같다.
5. mape
   1. 예측 값과 실제 값을 빼 후 실제 값으로 나눈 값의 평균 백분율로 표현하여  RSME의 단점을 해결
   2. 분모의 y가 0인 경우 무한대가 되는 문제
6. mae
   1. mse와 비슷
   2. 다만, 다른 점으로는 오차의 제곱값을 이용하는 것이 아닌 절대값을 이용하는 방법
7. R2 score
   1. 회귀 함수가 평균에 비해 얼마나 그 데이터를 잘 설명할 수 있는가에 대한 점수
   2. 편차 = 예측 값과 평균과의 거리
   3. 오차 = 예측 값과 회귀 직선과의 거리
   4. 일반적으로 0에서 1사이의 값이지만 예측이 심하게 어긋날 경우 - 값이 나올 수 있음
      1. '-'값이 나온다는 것은 회귀 직선이 평균보다 더 데이터를 잘 설명하지 못한다는 의미
8. 경사하강법
   1. 비용함수 = 오차 = MSE
   2. 우선 임의로 w값을 설정
      1. 최적의 w값을 찾아가기 위해서 시작점에서 손실 곡선의 기울기를 계산 -> 비용함수를 w에 대해서 편미분
      2. 파라미터를 곱한 것을 초기 설정된 w값에서 빼줌
      3. 학습률 :기울기의 보폭
         1. 학습률이 작으면 최적의 w를 찾는데, 오래 걸리고 크면 건너뛰어 버릴 수 있음
      4. 전체 데이터를 이용하여 경사를 구하기 때문에 최저점 수렴이 안정적
      5. 전체 데이터를 모두 한 번에 처리하기 때문에 속도가 느리고 메모리가 많이 필요
9. 확률적 경사하강법
   1. 전체 데이터 중 랜덤하게 선택된 하나의 데이터를 이용하여 경사하강법을 진행
   2. 작은 데이터로 학습할수 있고 최적화 속도가 빠름
   3. 하나의 데이터를 이용하기 때문에 기울기의 방향이 크게 바뀌고(오차율 증가) 최저점 안착이 비교적 힘듦 
10. 미니배치 확률적 경사하강법
    1. 경사하강법과 확률적 경사하강법의 절충안
    2. 전체 데이터를 batch_size개씩 나눠 학습