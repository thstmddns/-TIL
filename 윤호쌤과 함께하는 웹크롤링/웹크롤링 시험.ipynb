{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1 1\n",
    "1. a\n",
    "2. f\n",
    "3. c\n",
    "4. h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  문제 1 2\n",
    "[크롤링의 개념]\n",
    "크롤링은 SNS, 뉴스, 웹 정보 등 인터넷상에서 제공되는 웹문서의 정보를 수집하는 방식을\n",
    "의미한다. \n",
    "[크롤링의 필요성] \n",
    "크롤링이 필요한 이유는 많은 양, 빠른 속도, 정확성, 가치 등을 표방하는 5v를 충족시키기 \n",
    "위함이다. 크롤링을 통해 비정형데이터를 수집하고 가공하여 인사이트를 도출하는 활동은\n",
    "이전에는 활용하지 못했던 새로운 정보를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1 3\n",
    "BeautifulSoup 모듈은 크롤링을 하기 위한 대표적인 라이브러리이다.\n",
    "BeautifulSoup을 활용하여 웹페이지에서 원하는 데이터를 추출 가공하기 쉬운 상태로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1 4\n",
    "1번과 2의 차이점은 요소를 찾는 모듈인 find_element의 -s의 존재여부이다.\n",
    "만약 1번과 같이 -s가 없다면 하나의 값만 담을 수 있으며,\n",
    "반대로 -s가 붙으면 둘 이상의 값을 담을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13324ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1 5\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "res_HTML = req.get('HTML')\n",
    "bs_HTML = bs(res_HTML, 'lxml')\n",
    "suzip = bs_HTML.select('#this_span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 2 2\n",
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = wb.Chrome()\n",
    "driver.get('https://www.naver.com')\n",
    "search = driver.find_element(By.XPATH, '//*[@id=\"query\"]')\n",
    "search.send_keys('크롤링')\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제3 3\n",
    "import requests as req\n",
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "driver = wb.Chrome()\n",
    "driver.get('https://www.gmarket.co.kr/')\n",
    "driver.maximize_window()\n",
    "search = driver.find_element(By.XPATH, '//*[@id=\"desktop_layout-header\"]/div/div/div[2]/div[2]/ul/li[1]/a')\n",
    "search.click()\n",
    "\n",
    "name_list = []\n",
    "price_list = []\n",
    "\n",
    "\n",
    "name = driver.find_elements(By.XPATH, '//*[@id=\"gBestWrap\"]/div[2]/ul/li[1]')\n",
    "price = driver.find_elements(By.XPATH, '//*[@id=\"gBestWrap\"]/div[2]/ul/li[1]/div[2]/div[2]/strong')\n",
    "for i in range(20):\n",
    "    name_list.append(name.text)\n",
    "    price_list.append(price.text)\n",
    "print(len(name_list))\n",
    "print(len(price_list))\n",
    "g_df = {'상품명' : name_list,\n",
    "       '가격' : price_list}\n",
    "\n",
    "g_pd = pd.DataFrame(g_df)\n",
    "g_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0129ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 4 1\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.melon.com/chart/'\n",
    "req.get(url)\n",
    "\n",
    "\n",
    "\n",
    "head = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}\n",
    "melon_chart = req.get(url, headers = head)\n",
    "\n",
    "\n",
    "soup = bs(melon_chart.text, 'lxml')\n",
    "res = req.get('https://www.melon.com/chart/', headers = head)\n",
    "bsres = bs(res.text, 'lxml')\n",
    "titles_list = []\n",
    "artist_list = []\n",
    "artist = bsres.select('div.ellipsis.rank02>span')\n",
    "titles = soup.select('div.ellipsis.rank01>span>a')\n",
    "for i in range(100):\n",
    "    titles_list.append(titles[i].text)\n",
    "    artist_list.append(artist[i].text)\n",
    "\n",
    "melon_dic = {'타이틀' : titles_list,\n",
    "            '아티스트' : artist_list}\n",
    "melon_df = pd.DataFrame(melon_dic)\n",
    "melon_df.to_csv('C:/Users/user04/윤호쌤과 함께하는 웹크롤링/data/melon_chart.csv', encoding ='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fda73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "url = 'https://www.youtube.com/'\n",
    "req.get(url)\n",
    "youtube = req.get(url)\n",
    "\n",
    "soup = bs(youtube.text, 'lxml')\n",
    "res = req.get('https://www.youtube.com/')\n",
    "bsres = bs(res.text, 'lxml')\n",
    "driver = wb.Chrome()\n",
    "driver.get('https://www.youtube.com/')\n",
    "search = driver.find_element(By.XPATH, '//*[@id=\"search-input\"]')\n",
    "search.send_keys('웹')\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "title = []\n",
    "content = []\n",
    "content = bsres.select('div.ellipsis.rank02>span')\n",
    "title = soup.select('div.ellipsis.rank01>span>a')\n",
    "for i in range(100):\n",
    "    title.append(titles[i].text)\n",
    "    content.append(content[i].text)\n",
    "youtube_dic = {'제목' : title,\n",
    "            '내용' : content}\n",
    "youtube_df = pd.DataFrame(youtube_dic)\n",
    "youtube_df.to_csv('C:/Users/user04/윤호쌤과 함께하는 웹크롤링/data/melon_chart.csv', encoding ='euc-kr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
