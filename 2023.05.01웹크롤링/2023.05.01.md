### 웹크롤링

1. 웹사이트에 접근, 원하는 정보만 추출하는 기법
2. 자동화된 방식으로 인터넷 상의 웹페이지를 따라가며 데이터를 수집
   1. 더 쉬운 데이터 수집
   2. 자동화
   3. 시장분석
   4. 실시간 모니터링
3. 왜 파이썬을을 이용할까?
   1. 대용량 데이터 추출
   2. 편리함
   3. 직관적인 언어
4. 유의사항
   1. 인사이트 파악
   2. 개인정보 유의
   3. 이용약관 유념
5. 수집 데이터의 형태
   1. 정형 데이터
      1. 구조화가 잘 된 데이터
   2. 반정형 데이터
      1. 형태는 갖춰져있는데, 데이터끼리 연산이 불가능
         1. ex)지문
   3. 비정형 데이터
      1. 형태가 없는 데이터
         1. ex)형태가 없는 데이터
   4. 절차
      1. import requests as req
      2. 긁어오고자 하는 사이트의 주소를 입력
         1. res_melon = req.get('https://www.melon.com')
         2. 여기까지 하면 406에러가 발생한다.
         3. 이를 해결하기 위해 아래를 추가 진행
      3. 개발자 도구에서 User-Agent를 복사해서 딕셔너리 형태로 head라는 변수에 저장한다.
      4. 그런 다음 res_melon = req.get('https://www.melon.com', headers = head)로 저장한다.
6. Beautifulsoup
   1. 웹페이지의 HTML구조를 파싱, python Beautifulsoup객체로 변환
   2. requests로 가져온 data -> 분석할 수 있게 객체화
   3. 형태
      1. soup = Beautifulsoup(html, html.parser)
   4. 만약, 해당 집안이 어떤 집안이 모른다면?
      1. 타고타고 올라가서 부모를 알아보자
7. 순서
   1. 필요한 라이브러리를 import한다.
   2. request라이브러리를 활용하여 웹크롤링을 할 홈페이지 주소를 입력
   3. beautifulsoup을 이용하여 데이터를 활용하기 쉽게 정의
   4. select 함수를 활용하여 가져올 데이터의 위치를 입력