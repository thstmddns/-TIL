1. 오차역전파
   1. 순파
      1. 입력데이터를 입력층에서부터 출력층에서부터 출력층까지 정방향으로 이동시키며 예측해나가는 과정
   2. 역전파
      1. 출력층부터 발생한 에러를 입력층 쪽으로 전파시키면서 최적의 결과를 위해 신경망의 가중치를 학습해 나가는 과정
2. 손실함수
   1. 신경망 학습을 위해서는 경사하강법을 사용
3. 시그모이드 함수의 문제점
   1. 기울기 소실의 문제
      1. 역전파를 거듭해서 진행하다보면 어느순간 0에 가까운 에러를 인식하게 된다.
4. 최적화함수
   1. 경사하강법
      1. 모든데이터를 이용해 업데이트
   2. 확률적 경사하강법
      1. 확률적으로 선택된 하나의 데이터를 이용해 업데이트
      2. 경사하강법에 비해 안정성은 떨어지지만 속도는 빠르다
5. 배치사이즈
   1. 일반적으로 pc메모리의 한계 및 속도 저하 때문에 대부분의 경우에는 한번에 epoch에 모든 데이터를 한꺼번에 집어넣기 힘듦
   2. 배치사이즈를 줄임
      1. 메모리소모가 적음
      2. 학습속도가 느임
      3. 학습속도가 느린 만큼 좀 더 정확하게 학습
   3. 배치사이즈를 늘림
      1. 메모리 소모가 큼
      2. 학습속도가 빠름
      3. 정확도가 낮음
   4. 디폴트 값은 32
6. 모멘텀
   1. 경사하강법에 관성의 법칙을 적용해 현재batch 뿐만 아니라 이전 batch의 데이터까지 업데이트에 반영
   2. 가중치를 수정하기 전 이전 방향을 참고하여 업데이트
7. 합성곱신경망(CNN)
   1. 데니터의 특징들을 추출하는 
   2. MLP의 단점을 개선하기 위해 등장
      1. MLP는 이미지의 위치에 민감하게 동작하며 위치에 종속적인 결과를 얻게 됨
      2.  MLP로 이미지 인식을 하려면 크기와 위치를 비슷하게 맞춰야 함
      3. 그래서 특징을 추출해서 비교하는 CNN이 대두되게 됨
   3. 