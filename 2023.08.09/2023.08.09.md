1. 규제
   1. 선형 회귀 모델에서 과대적합의 위험을 감소시키기 위해 w값의 비중을 줄이는 것
   2. 선형 회귀
      1. 선형회귀 모델은 학습데이터를 전부 반영하여 하나의 직선 방정식을 만들게 됨 -> 학습데이터에 대한 과대 적합이 되는 것을 방지할 수 있는 방법이 없음
   3. 모델 정규화
      1. w값이 크다 = 입력에 따른 예측 결과가 크게 바뀜 -. 새로운 데이터가 들어오면 제대로 얘측하지 못할 수 있음 = 과대적합의 위험이 있음
      2. w 값을 적절히 낮게 조절하여 과대적합의 위험을 줄이는 것이 규제의 핵심
      3. L1 규제 : Lasso
         1. w의 모든 원소에 똑같은 힘으로 규제를 적용하는 방법. 특정 계수들은 0이 됨.
         2. 특성선택이 자동으로 이루어진다.
         3. 중요하지 않은 변수는 제외
         4. 특성 간 상관관계가 상대적으로 낮은 경우 사용
      4. L2 규제 : Ridge
         1. w의 모든 원소에 골고루 규제를 적용하여 0에 가깝게 만든다.
         2. 모든 변수에 같은 비율로 규제를 적용
         3. 특성 간 상관관계가 상대적으로 높은 경우 사용
      5. L1 + L2 엘라스틱넷
         1. L1 규제로 변수를 줄이고 L2 규제로 남은 변수들의 영향도를 줄임
         2. 특성 수가 데이터 수보다 많을 때 사용
      6. 주요 매개변수
         1. alpha
            1. alpha 값이 커지면 규제의 효과가 커짐(과대적합 감소, 오차증가)
            2. alpha 값이 작아지면 규제의 효과가 작아짐(과대적합 증가, 오차 감소)
2. Logistic Regression
   1. 선형모델 방식을 기반으로 이진 분류를 수행하는 모델
   2. 선형 모델은 간단한 함수식을 사용하기 때문에 학습 및 예측속도가 빠르다.
   3. 매우 큰 데이터 세트에서도 잘 동작한다.
   4. 일반적으로 특성이 많을수록 더 잘 동작한다.
      1. 그러나 특성이 적은 데이터에서는 다른 모델이 더 좋은 경우가 많다.
   5. 선형회귀 직선을 사용하여 두 집단을 분류할 수 있다는 점에서 착안함
   6. sigmoid 함수
      1. sigmoid 함수를 사용하여 례측하면 0!1 사이의 확률정보로 표시가능
      2. 0.5기준으로 낮으면 0, 높으면 1로 예측
   7. 

